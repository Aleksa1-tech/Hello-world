{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise_3_3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleksa1-tech/Hello-world/blob/master/Copy_of_Exercise_3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9iIFPb3tljn"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "#Exercise 3.3\n",
        "\n",
        "In this exercise we train a network to classify vowels from formant data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVukh7MYtnbO"
      },
      "source": [
        "(a) Load in vowels data set and prepare for learning. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbGbZU26taor"
      },
      "source": [
        "# Import the necessary modules/libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Import the data as csv file\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/vowels.csv\")\n",
        "\n",
        "# See the top rows of the data uploaded\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK-hRoznuFLQ"
      },
      "source": [
        "---\n",
        "(b) Convert SEX column to a number. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCscBUwRuLCH"
      },
      "source": [
        "# Makes sex a categorical variable (instead of string)\n",
        "df[\"SEX\"]=df.SEX.astype('category')\n",
        "# convert SEX column to the numerical codes\n",
        "df[\"SEX\"]=df.SEX.cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn3ciETyucIm"
      },
      "source": [
        "---\n",
        "(c) Copy all numbers into numpy array and standardise. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbtFgyqKWfqi"
      },
      "source": [
        "#print(X)\n",
        "print(df.iloc[:,3:7])\n",
        "X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5nRPtCnumjm"
      },
      "source": [
        "# Choose the necessary columns 3 to 6 for all rows\n",
        "X=np.array(df.iloc[:,3:7])\n",
        "print(X)\n",
        "\n",
        "# Standardise by substructing mean and dividing by the standard deviation\n",
        "for i in range(X.shape[1]):\n",
        "  X[:,i]=(X[:,i]-np.mean(X[:,i]))/np.std(X[:,i])\n",
        "print(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjl_gZo1v04n"
      },
      "source": [
        "---\n",
        "(d) Convert vowels to one hot coding. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9sIC-Kwv5AO"
      },
      "source": [
        "#Convert vowel from strings to categories\n",
        "df[\"VOWEL\"]=df.VOWEL.astype('category')\n",
        "# convert vowels to the numerical categories and print first ten of them\n",
        "vowels=df.VOWEL.cat.codes\n",
        "print(vowels[:10])\n",
        "#Convert numerical code to one-hot coding\n",
        "vowelcode = to_categorical(vowels)\n",
        "print(vowelcode[:10])\n",
        "# record number of vowels in a dataset \n",
        "nvowel=vowelcode.shape[1]\n",
        "print(nvowel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaactudHypBN"
      },
      "source": [
        "---\n",
        "(e) Divide the data into train and test. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujmsK0JFzPmf"
      },
      "source": [
        "print(X)\n",
        "X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p67qMATxlnW"
      },
      "source": [
        "# select 80% of the data for training and 20% for testing\n",
        "ntrain=int(0.8*X.shape[0])\n",
        "# get a random permutation of the samples\n",
        "indices = np.random.permutation(X.shape[0])\n",
        "# select samples to use for training / these are the main data for testing and training\n",
        "Xtrain,Xtest = X[indices[:ntrain],:], X[indices[ntrain:],:]\n",
        "# select samples to use for testing / these are basically labes for training and testing\n",
        "ytrain,ytest = vowelcode[indices[:ntrain],:], vowelcode[indices[ntrain:],:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A5F1Ttcw1nP"
      },
      "source": [
        "---\n",
        "(f) Build a classifier network with configurable number of inputs and outputs. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZaFcKI4xAM2"
      },
      "source": [
        "# define a function for a model\n",
        "def build_model(numinput,numhidden,numoutput):\n",
        "  # define the type of a ML model\n",
        "  model=Sequential()\n",
        "  # add a first layer defining s number of hidden layers and numinput units\n",
        "  model.add(Dense(numhidden,activation='sigmoid',input_shape=(numinput,),name=\"hidden_layer\"))\n",
        "  # add an output layer defining the number of final outputs - build as softmax output\n",
        "  model.add(Dense(numoutput,activation='softmax',name=\"output_layer\"))\n",
        "  # define the learning rate and momentum / suitable optimizer\n",
        "  sgd=SGD(learning_rate=0.1, momentum=0.9)\n",
        "  # compile the model defining the loss function and optimisation alghorithm\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hr9M4IvysFU"
      },
      "source": [
        "---\n",
        "(g) Train the network. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3vgpaqpJTY"
      },
      "source": [
        "Xtrain.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YONJ4Z-jy3ll"
      },
      "source": [
        "# build a model with 4 inputs, 32 hidden layers and the number of vowels equal to a given number\n",
        "model=build_model(Xtrain.shape[1],32,nvowel);\n",
        "# fit the model based on the training data and validate it on testing data, returning history\n",
        "hist=model.fit(Xtrain,ytrain,validation_data=(Xtest,ytest),epochs=100,batch_size=16,verbose=0)\n",
        "# evaluate the performance of th model on the trainig data\n",
        "print(model.evaluate(Xtrain,ytrain,verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZMVEXy23Nt"
      },
      "source": [
        "---\n",
        "(h) Plot training curves. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR-xDcd7283U"
      },
      "source": [
        "# define the figure size\n",
        "plt.figure(figsize=(10,4))\n",
        "# plotting next to each other, define the first subplot\n",
        "plt.subplot(1,2,1)\n",
        "# plot loss over trainig batches for training loss and validation loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"loss\",\"val_loss\"])\n",
        "# plotting next to each other define the second subplot\n",
        "plt.subplot(1,2,2)\n",
        "# plot accuracies over training batches for training and validation\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"accuracy\",\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6fRtoY0ABe"
      },
      "source": [
        "---\n",
        "(i) Calculate performance on test data. Run the code then add comments to explain how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNhtTzuE0DXl"
      },
      "source": [
        "# predict the vowels for the testing data by ML / predict the vowel codes\n",
        "vowelcodepred=model.predict(Xtest)\n",
        "print(vowelcodepred)\n",
        "# state the real values of vowels / predict the true vowels from the test labels\n",
        "voweltrue=np.argmax(ytest,axis=1)\n",
        "print(voweltrue)\n",
        "# predict vowels takinf the ones with maximum probability as found by the model / get the most probable values in each row\n",
        "vowelpred=np.argmax(vowelcodepred,axis=1)\n",
        "print(vowelpred)\n",
        "# get the total number of vowels predicted / in the test data\n",
        "total=ytest.shape[0]\n",
        "# get the percentage correct of the vowels predicted\n",
        "correct=np.sum(voweltrue==vowelpred)\n",
        "print(\"Correct %d/%d (%.1f%%)\" % (correct,total,100.0*correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7QmdT1GISfh"
      },
      "source": [
        "---\n",
        "(j) Experiment with changing the number of hidden units, the number of training epochs and the optimizer parameters to see their effect on test set performance."
      ]
    }
  ]
}